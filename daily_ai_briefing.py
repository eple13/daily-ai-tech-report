#!/usr/bin/env python3
"""
Daily AI Briefing Generator
ë§¤ì¼ ì•„ì¹¨ 9ì‹œ ìë™ ì‹¤í–‰ - Claude APIë¡œ ë¸Œë¦¬í•‘ ìƒì„± í›„ Notion DB ì—…ë°ì´íŠ¸

Requirements:
    pip install anthropic requests python-dotenv

Environment Variables:
    ANTHROPIC_API_KEY: Claude API í‚¤
    NOTION_API_KEY: Notion Integration í† í°
    NOTION_DATABASE_ID: AI Research Updates ë°ì´í„°ë² ì´ìŠ¤ ID
"""

import os
import json
import re
import logging
import time
from datetime import datetime, timezone, timedelta
from typing import Optional
import anthropic
import requests
from dotenv import load_dotenv

load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Logging ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
LOG_FILE = os.getenv("LOG_FILE", "briefing.log")

logger = logging.getLogger("daily_ai_briefing")
logger.setLevel(getattr(logging, LOG_LEVEL, logging.INFO))

formatter = logging.Formatter(
    "%(asctime)s [%(levelname)s] %(message)s", datefmt="%Y-%m-%d %H:%M:%S"
)

console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

file_handler = logging.FileHandler(LOG_FILE, encoding="utf-8")
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration (í™˜ê²½ë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
NOTION_API_KEY = os.getenv("NOTION_API_KEY")
NOTION_DATABASE_ID = os.getenv("NOTION_DATABASE_ID")

NOTION_API_URL = "https://api.notion.com/v1"
NOTION_VERSION = "2022-06-28"

CLAUDE_MODEL = os.getenv("CLAUDE_MODEL", "claude-sonnet-4-20250514")
CLAUDE_MAX_TOKENS = int(os.getenv("CLAUDE_MAX_TOKENS", "8000"))
API_TIMEOUT = int(os.getenv("API_TIMEOUT", "30"))
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "3"))

# KST ì‹œê°„ëŒ€
KST = timezone(timedelta(hours=9))

# Briefing prompt
BRIEFING_PROMPT = """AI Product Owner ì‹œê°ì—ì„œ, ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ ìµœì‹  AI ì‹œì¥Â·ì—°êµ¬ ë‰´ìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¸Œë¦¬í•‘ì„ ì‘ì„±í•´ì¤˜.

ì¤‘ë³µ ë°©ì§€ ì›ì¹™:
1) ê°™ì€ ì‚¬ê±´ì„ ë‹¤ë¥¸ í‘œí˜„ìœ¼ë¡œ ë°˜ë³µí•˜ì§€ ë§ê³  í•˜ë‚˜ì˜ í•­ëª©ìœ¼ë¡œ í†µí•©í•´ì¤˜.
2) ì´ë¯¸ ë„ë¦¬ ì•Œë ¤ì§„ ì˜¤ë˜ëœ ì´ìŠˆì˜ ì¬ìš”ì•½ì€ ì œì™¸í•˜ê³ , ìµœê·¼ 7ì¼ ë‚´ ìƒˆë¡­ê²Œ í™•ì¸ëœ ì‚¬ì‹¤/ë°œí‘œ/ì§€í‘œ ë³€í™” ìœ„ì£¼ë¡œ ì„ ë³„í•´ì¤˜.
3) í•­ëª© ê°„ í•µì‹¬ í¬ì¸íŠ¸ê°€ ê²¹ì¹˜ë©´ ë” ì˜í–¥ë„ê°€ í° í•­ëª©ë§Œ ë‚¨ê²¨ì¤˜.

ì½˜í…ì¸  êµ¬ì„± ì›ì¹™:
- ì—°êµ¬(ë…¼ë¬¸/ê¸°ìˆ )ì™€ ì‹œì¥(ê¸°ì—…/ì œí’ˆ/íˆ¬ì/ê·œì œ) ê´€ì ì„ ê· í˜• ìˆê²Œ í¬í•¨í•´ì¤˜.
- ê° í•­ëª©ì€ "ë¬´ì—‡ì´ ìƒˆë¡­ê³  ì™œ ì¤‘ìš”í•œì§€"ê°€ ë“œëŸ¬ë‚˜ë„ë¡ 2-3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ì¤˜.
- ì„¤ëª…ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë…¼ë¬¸Â·ê³µì‹ ë°œí‘œÂ·ì‹ ë¢° ê°€ëŠ¥í•œ ê¸°ì‚¬ ë§í¬ë¥¼ referencesì— í¬í•¨í•´ì¤˜.

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì¤˜:

```json
{
  "items": [
    {
      "title": "í•­ëª© ì œëª©",
      "category": "ğŸ“„ ë…¼ë¬¸/ì—°êµ¬" | "ğŸš€ ëª¨ë¸ ë¦´ë¦¬ìŠ¤" | "ğŸ“Š ë²¤ì¹˜ë§ˆí¬" | "ğŸ’¼ ì‹œì¥/ê¸°ì—…" | "ğŸ”§ ê¸°ìˆ /ì¸í”„ë¼",
      "importance": "ğŸ”¥ High" | "â­ Medium" | "ğŸ“Œ Low",
      "tags": ["íƒœê·¸1", "íƒœê·¸2"],
      "summary": "2-3ë¬¸ì¥ ìš”ì•½",
      "source_url": "ì¶œì²˜ URL (ìˆëŠ” ê²½ìš°)"
    }
  ],
  "references": [
    "[1] ì°¸ê³ ë¬¸í—Œ ì„¤ëª… - URL",
    "[2] ì°¸ê³ ë¬¸í—Œ ì„¤ëª… - URL"
  ]
}
```

íƒœê·¸ëŠ” ììœ ë¡­ê²Œ ìƒì„± ê°€ëŠ¥í•˜ë©°, ì´ìŠˆì˜ í•µì‹¬ ì£¼ì œë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” ì§§ì€ í‚¤ì›Œë“œ 1-3ê°œë¥¼ ì‚¬ìš©í•´ì¤˜.

ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ì„ í™œìš©í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ì¦í•˜ê³ , ì¤‘ë³µ ì—†ëŠ” ì¤‘ìš”í•œ ì—…ë°ì´íŠ¸ 3-5ê°œë§Œ í¬í•¨í•´ì¤˜."""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VALID_CATEGORIES = {
    "ğŸ“„ ë…¼ë¬¸/ì—°êµ¬", "ğŸš€ ëª¨ë¸ ë¦´ë¦¬ìŠ¤", "ğŸ“Š ë²¤ì¹˜ë§ˆí¬", "ğŸ’¼ ì‹œì¥/ê¸°ì—…", "ğŸ”§ ê¸°ìˆ /ì¸í”„ë¼"
}
VALID_IMPORTANCES = {"ğŸ”¥ High", "â­ Medium", "ğŸ“Œ Low"}


def retry_with_backoff(func, max_retries: int = MAX_RETRIES, base_delay: float = 2.0):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì ìš©í•œ ì¬ì‹œë„ ë˜í¼"""
    last_exception = None
    for attempt in range(max_retries + 1):
        try:
            return func()
        except Exception as e:
            last_exception = e
            if attempt < max_retries:
                delay = base_delay * (2 ** attempt)
                logger.warning(
                    "Attempt %d/%d failed: %s â€” retrying in %.1fs",
                    attempt + 1, max_retries + 1, e, delay,
                )
                time.sleep(delay)
            else:
                logger.error(
                    "All %d attempts failed. Last error: %s",
                    max_retries + 1, e,
                )
    raise last_exception


def validate_item(item: dict) -> dict:
    """ë¸Œë¦¬í•‘ í•­ëª©ì˜ í•„ìˆ˜ í•„ë“œë¥¼ ê²€ì¦í•˜ê³  ê¸°ë³¸ê°’ìœ¼ë¡œ ë³´ì™„"""
    if not isinstance(item, dict):
        return None

    title = item.get("title", "").strip()
    if not title:
        logger.warning("Item skipped: missing title")
        return None

    category = item.get("category", "ğŸ“„ ë…¼ë¬¸/ì—°êµ¬")
    if category not in VALID_CATEGORIES:
        logger.warning("Invalid category '%s' for '%s', defaulting", category, title)
        category = "ğŸ“„ ë…¼ë¬¸/ì—°êµ¬"

    importance = item.get("importance", "â­ Medium")
    if importance not in VALID_IMPORTANCES:
        logger.warning("Invalid importance '%s' for '%s', defaulting", importance, title)
        importance = "â­ Medium"

    return {
        "title": title[:100],
        "category": category,
        "importance": importance,
        "tags": item.get("tags", []),
        "summary": item.get("summary", ""),
        "source_url": item.get("source_url", ""),
    }


def parse_json_response(text: str) -> Optional[dict]:
    """Claude ì‘ë‹µì—ì„œ JSONì„ ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
    # 1) ```json ... ``` ì½”ë“œë¸”ë¡
    json_match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group(1))
        except json.JSONDecodeError:
            logger.warning("JSON code block found but failed to parse")

    # 2) ê°€ì¥ ë°”ê¹¥ìª½ { } ë¸”ë¡ (balanced braces)
    depth = 0
    start = None
    for i, ch in enumerate(text):
        if ch == '{':
            if depth == 0:
                start = i
            depth += 1
        elif ch == '}':
            depth -= 1
            if depth == 0 and start is not None:
                try:
                    return json.loads(text[start:i + 1])
                except json.JSONDecodeError:
                    start = None

    # 3) ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        logger.warning("Could not parse JSON from response")
        logger.debug("Response preview: %s", text[:500])
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Notion ì¤‘ë³µ ì²´í¬
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def check_existing_titles(date_str: str) -> set:
    """ì˜¤ëŠ˜ ë‚ ì§œë¡œ ì´ë¯¸ ë“±ë¡ëœ í•­ëª© ì œëª© ì§‘í•©ì„ ë°˜í™˜"""
    if not NOTION_API_KEY or not NOTION_DATABASE_ID:
        return set()

    headers = {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_VERSION,
    }

    query = {
        "filter": {
            "property": "Date",
            "date": {"equals": date_str},
        },
        "page_size": 100,
    }

    try:
        resp = requests.post(
            f"{NOTION_API_URL}/databases/{NOTION_DATABASE_ID}/query",
            headers=headers,
            json=query,
            timeout=API_TIMEOUT,
        )
        if resp.status_code != 200:
            logger.warning("Failed to query existing titles: %s", resp.status_code)
            return set()

        results = resp.json().get("results", [])
        titles = set()
        for page in results:
            title_prop = page.get("properties", {}).get("Title", {}).get("title", [])
            if title_prop:
                titles.add(title_prop[0].get("text", {}).get("content", ""))
        logger.info("Found %d existing items for %s", len(titles), date_str)
        return titles
    except Exception as e:
        logger.warning("Error checking existing titles: %s", e)
        return set()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Core Functions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def generate_briefing_with_claude() -> Optional[dict]:
    """Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ AI ë¸Œë¦¬í•‘ ìƒì„± (ì¬ì‹œë„ í¬í•¨)"""
    if not ANTHROPIC_API_KEY:
        logger.error("ANTHROPIC_API_KEY not set")
        return None

    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)

    def _call_claude():
        response = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=CLAUDE_MAX_TOKENS,
            tools=[
                {
                    "type": "web_search_20250305",
                    "name": "web_search",
                }
            ],
            messages=[
                {"role": "user", "content": BRIEFING_PROMPT}
            ],
        )

        full_response = ""
        for block in response.content:
            if hasattr(block, "text"):
                full_response += block.text

        result = parse_json_response(full_response)
        if result is None:
            raise ValueError("Failed to parse JSON from Claude response")
        return result

    try:
        return retry_with_backoff(_call_claude)
    except Exception as e:
        logger.error("Claude API call failed after retries: %s", e)
        return None


def add_to_notion_database(item: dict, references: list) -> bool:
    """Notion ë°ì´í„°ë² ì´ìŠ¤ì— í•­ëª© ì¶”ê°€ (ì¬ì‹œë„ í¬í•¨)"""
    if not NOTION_API_KEY:
        logger.error("NOTION_API_KEY not set")
        return False

    if not NOTION_DATABASE_ID:
        logger.error("NOTION_DATABASE_ID not set")
        return False

    headers = {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_VERSION,
    }

    # ì°¸ê³ ë¬¸í—Œì„ ìš”ì•½ì— ì¶”ê°€
    summary_with_refs = item.get("summary", "")
    if references:
        summary_with_refs += "\n\nì°¸ê³ : " + " | ".join(references[:3])

    # íƒœê·¸ ì •ê·œí™”
    tags = item.get("tags", [])
    if not isinstance(tags, list):
        tags = []

    normalized_tags = []
    for tag in tags:
        if not isinstance(tag, str):
            continue
        cleaned = tag.strip()
        if cleaned and cleaned not in normalized_tags:
            normalized_tags.append(cleaned)

    # KST ê¸°ì¤€ ë‚ ì§œ ì‚¬ìš©
    today_kst = datetime.now(KST).strftime("%Y-%m-%d")

    # Notion í˜ì´ì§€ ë°ì´í„° êµ¬ì„±
    page_data = {
        "parent": {"database_id": NOTION_DATABASE_ID},
        "properties": {
            "Title": {
                "title": [{"text": {"content": item.get("title", "Untitled")[:100]}}]
            },
            "Category": {
                "select": {"name": item.get("category", "ğŸ“„ ë…¼ë¬¸/ì—°êµ¬")}
            },
            "Date": {
                "date": {"start": today_kst}
            },
            "Importance": {
                "select": {"name": item.get("importance", "â­ Medium")}
            },
            "Summary": {
                "rich_text": [{"text": {"content": summary_with_refs[:2000]}}]
            },
            "Tags": {
                "multi_select": [{"name": tag} for tag in normalized_tags]
            },
        },
    }

    # Source URL ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
    source_url = item.get("source_url", "")
    if source_url and source_url.startswith("http"):
        page_data["properties"]["Source"] = {"url": source_url}

    def _post_to_notion():
        response = requests.post(
            f"{NOTION_API_URL}/pages",
            headers=headers,
            json=page_data,
            timeout=API_TIMEOUT,
        )

        if response.status_code in (200, 201):
            return True

        # Rate limit ì‹œ ì¬ì‹œë„ë¥¼ ìœ„í•´ ì˜ˆì™¸ ë°œìƒ
        if response.status_code == 429:
            raise RuntimeError(f"Notion rate limit: {response.text[:200]}")

        # ê·¸ ì™¸ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„ ì—†ì´ ì‹¤íŒ¨ ì²˜ë¦¬
        logger.error(
            "Notion API error for '%s': %s â€” %s",
            item.get("title", "Untitled"),
            response.status_code,
            response.text[:300],
        )
        return False

    try:
        result = retry_with_backoff(_post_to_notion, max_retries=2, base_delay=1.0)
        if result:
            logger.info("Added: %s", item.get("title", "Untitled"))
        return result
    except Exception as e:
        logger.error("Failed to add '%s' to Notion: %s", item.get("title", "Untitled"), e)
        return False


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Main
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("=" * 60)
    logger.info("Daily AI Briefing - %s", datetime.now(KST).strftime("%Y-%m-%d %H:%M KST"))
    logger.info("=" * 60)

    # 1. Claude APIë¡œ ë¸Œë¦¬í•‘ ìƒì„±
    logger.info("Generating briefing with Claude API (model: %s)...", CLAUDE_MODEL)
    briefing = generate_briefing_with_claude()

    if not briefing:
        logger.error("Failed to generate briefing")
        return 1

    items = briefing.get("items", [])
    references = briefing.get("references", [])

    # 2. í•­ëª© ê²€ì¦
    validated_items = []
    for item in items:
        validated = validate_item(item)
        if validated:
            validated_items.append(validated)
        else:
            logger.warning("Dropped invalid item: %s", item)

    logger.info("Generated %d valid items (of %d total)", len(validated_items), len(items))

    if not validated_items:
        logger.error("No valid items to add")
        return 1

    # 3. ì¤‘ë³µ ì²´í¬
    today_kst = datetime.now(KST).strftime("%Y-%m-%d")
    existing_titles = check_existing_titles(today_kst)

    new_items = []
    for item in validated_items:
        if item["title"] in existing_titles:
            logger.info("Skipping duplicate: %s", item["title"])
        else:
            new_items.append(item)

    if not new_items:
        logger.info("All items already exist in Notion â€” nothing to add")
        return 0

    logger.info("%d new items to add (skipped %d duplicates)",
                len(new_items), len(validated_items) - len(new_items))

    # 4. Notion ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€
    logger.info("Adding items to Notion database...")

    success_count = 0
    for item in new_items:
        if add_to_notion_database(item, references):
            success_count += 1

    # 5. ê²°ê³¼ ìš”ì•½
    logger.info("=" * 60)
    logger.info("Summary: %d/%d items added successfully", success_count, len(new_items))
    logger.info("=" * 60)

    return 0 if success_count == len(new_items) else 1


if __name__ == "__main__":
    exit(main())
